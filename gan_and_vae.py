# -*- coding: utf-8 -*-
"""Gan and Vae.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a7v4RIIViPFx8ZqnrpmMNgKy_XEa-ANh
"""

import tensorflow as tf
from tensorflow.keras import layers

# Define the generator model
def build_generator():
    model = tf.keras.Sequential()
    model.add(layers.Dense(128, activation='relu', input_dim=100))
    model.add(layers.Dense(784, activation='sigmoid'))
    model.add(layers.Reshape((28, 28)))
    return model

# Define the discriminator model
def build_discriminator():
    model = tf.keras.Sequential()
    model.add(layers.Flatten(input_shape=(28, 28)))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model

# Combine models to create the GAN
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = tf.keras.Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# Load MNIST dataset
(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train / 255.0  # Normalize data
x_train = x_train.reshape(-1, 28, 28)

# Compile models
generator = build_generator()
discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

gan = build_gan(generator, discriminator)
gan.compile(loss='binary_crossentropy', optimizer='adam')

# Train the GAN (simplified)
import numpy as np

def train_gan(epochs=10000, batch_size=128):
    half_batch = batch_size // 2
    for epoch in range(epochs):
        noise = np.random.randn(half_batch, 100)
        generated_images = generator.predict(noise)
        real_images = x_train[np.random.randint(0, x_train.shape[0], half_batch)]

        labels_real = np.ones((half_batch, 1))
        labels_fake = np.zeros((half_batch, 1))

        d_loss_real = discriminator.train_on_batch(real_images, labels_real)
        d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        noise = np.random.randn(batch_size, 100)
        labels_gan = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(noise, labels_gan)

        if epoch % 1000 == 0:
            print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]")

train_gan()

from tensorflow.keras import layers, Model
from tensorflow.keras import backend as K
import tensorflow as tf

# Encoder network
def build_encoder():
    inputs = layers.Input(shape=(28, 28, 1))
    x = layers.Flatten()(inputs)
    x = layers.Dense(128, activation='relu')(x)
    z_mean = layers.Dense(2)(x)
    z_log_var = layers.Dense(2)(x)
    return Model(inputs, [z_mean, z_log_var])

# Sampling function (reparameterization trick)
def sampling(args):
    z_mean, z_log_var = args
    batch = K.shape(z_mean)[0]
    dim = K.int_shape(z_mean)[1]
    epsilon = K.random_normal(shape=(batch, dim))
    return z_mean + K.exp(0.5 * z_log_var) * epsilon

# Decoder network
def build_decoder():
    latent_inputs = layers.Input(shape=(2,))
    x = layers.Dense(128, activation='relu')(latent_inputs)
    x = layers.Dense(784, activation='sigmoid')(x)
    outputs = layers.Reshape((28, 28, 1))(x)
    return Model(latent_inputs, outputs)

# VAE model
def build_vae(encoder, decoder):
    inputs = layers.Input(shape=(28, 28, 1))
    z_mean, z_log_var = encoder(inputs)
    z = layers.Lambda(sampling)([z_mean, z_log_var])
    reconstructed = decoder(z)
    vae = Model(inputs, reconstructed)

    xent_loss = K.binary_crossentropy(K.flatten(inputs), K.flatten(reconstructed))
    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
    vae_loss = K.mean(xent_loss + kl_loss)
    vae.add_loss(vae_loss)
    vae.compile(optimizer='adam')
    return vae

# Prepare the dataset (MNIST)
(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)

# Instantiate models
encoder = build_encoder()
decoder = build_decoder()
vae = build_vae(encoder, decoder)

# Train the VAE
vae.fit(x_train, epochs=10, batch_size=128)