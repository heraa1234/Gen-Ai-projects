# -*- coding: utf-8 -*-
"""Generate Image Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tbaHsDT2pIKA3n31Y3B4_pJt7LblqFaJ

**Set up the Dataset**
"""

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define data transformation
transform = transforms.Compose([
    transforms.Resize(32),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load CIFAR-10 dataset
dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

""" **Define the GAN Model**"""

import torch.nn as nn

# Define the generator network
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 3 * 32 * 32),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.main(x)
        return x.view(-1, 3, 32, 32)

# Define the discriminator network
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(3 * 32 * 32, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = x.view(-1, 3 * 32 * 32)
        return self.main(x)

"""**Train the GAN Model**

"""

import torch.optim as optim

# Hyperparameters
latent_dim = 100
lr = 0.0002
num_epochs = 50

# Initialize models and optimizers
generator = Generator(latent_dim)
discriminator = Discriminator()
criterion = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)

# Training loop
for epoch in range(num_epochs):
    for real_images, _ in dataloader:
        # Train Discriminator
        optimizer_D.zero_grad()
        real_images = real_images.view(-1, 3 * 32 * 32)
        real_labels = torch.ones(real_images.size(0), 1)
        fake_labels = torch.zeros(real_images.size(0), 1)

        # Discriminator on real images
        outputs = discriminator(real_images)
        loss_real = criterion(outputs, real_labels)

        # Discriminator on fake images
        z = torch.randn(real_images.size(0), latent_dim)
        fake_images = generator(z)
        outputs = discriminator(fake_images.detach())
        loss_fake = criterion(outputs, fake_labels)

        # Backprop and optimize
        loss_D = loss_real + loss_fake
        loss_D.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        outputs = discriminator(fake_images)
        loss_G = criterion(outputs, real_labels)
        loss_G.backward()
        optimizer_G.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss D: {loss_D.item()}, Loss G: {loss_G.item()}')

"""**Generate new Images**

"""

import matplotlib.pyplot as plt

# Generate and display images
z = torch.randn(16, latent_dim)
generated_images = generator(z).detach()

# Convert the images to [0, 1] range for visualization
generated_images = (generated_images + 1) / 2

# Display images
fig, axes = plt.subplots(4, 4, figsize=(8, 8))
for i, ax in enumerate(axes.flatten()):
    ax.imshow(generated_images[i].permute(1, 2, 0).cpu().numpy())
    ax.axis('off')
plt.show()

